# services/openai_generator.py

import os
import json
import logging
import re
from pathlib import Path
from typing import Dict, Optional, List
from functools import lru_cache

from dotenv import load_dotenv
load_dotenv()

from openai import OpenAI
from openai.types.chat import ChatCompletionMessage
from jsonschema import validate, ValidationError

from models.types import (
    DraftInput,
    RecommendationResponse,
    DetailedBuildResponse,
    BuildVariant,
)
from services.logic import (
    generate_recommendation,
    fallback_detailed_build,
)
from services.prompt_builder import PromptBuilder
from services.cache import load_build_from_cache, save_build_to_cache

SCHEMA_PATH = Path(__file__).parent.parent / "models" / "openai_response_schema.json"
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
TEMPERATURE = float(os.getenv("OPENAI_TEMP", "0.7"))
MAX_TOKENS = int(os.getenv("OPENAI_MAX_TOKENS", "2000"))

logger = logging.getLogger(__name__)

# ---------------------------- Helpers ----------------------------

def extract_json_block(text: str) -> str:
    match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", text.strip(), re.DOTALL)
    return match.group(1) if match else text.strip()


@lru_cache()
def get_openai_client() -> OpenAI:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or not api_key.startswith("sk-"):
        raise ValueError("‚ùå OPENAI_API_KEY is missing or invalid.")
    logger.info(f"üîë OpenAI key detected: {api_key[:10]}... (length: {len(api_key)})")
    return OpenAI(api_key=api_key)


def validate_openai_json(data: Dict) -> bool:
    try:
        with open(SCHEMA_PATH, "r", encoding="utf-8") as f:
            schema = json.load(f)
        validate(instance=data, schema=schema)
        return True
    except ValidationError as ve:
        logger.warning(f"‚ö†Ô∏è OpenAI response schema validation failed: {ve.message}")
        logger.debug(json.dumps(data, indent=2, ensure_ascii=False))
        return False


def chat_completion(system_msg: str, user_msg: str, max_tokens: int = MAX_TOKENS) -> Optional[ChatCompletionMessage]:
    try:
        client = get_openai_client()
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=TEMPERATURE,
            max_tokens=max_tokens,
        )
        return response.choices[0].message if response.choices else None
    except Exception as e:
        logger.exception(f"üí• OpenAI error: {e}")
        return None

# ---------------------------- Recommendation ----------------------------

def generate_openai_recommendation(draft: DraftInput) -> RecommendationResponse:
    builder = PromptBuilder()
    prompt = builder.build_recommend_prompt(draft)

    response = chat_completion(system_msg=builder.templates["base"], user_msg=prompt)
    if not response:
        return generate_recommendation(draft)

    content = extract_json_block(response.content)
    if content.lower() in ("null", "none", ""):
        return generate_recommendation(draft)

    try:
        parsed = json.loads(content)
        if validate_openai_json(parsed):
            return RecommendationResponse(**parsed)
    except Exception as e:
        logger.exception(f"üíÄ Recommendation JSON parsing failed: {e}")

    return generate_recommendation(draft)

# ---------------------------- Build Options ----------------------------

def generate_build_options(
    hero: str,
    role: str,
    aspect: str,
    enemy_lane_heroes: List[str]
) -> List[BuildVariant]:
    user_prompt = (
        f"–ì–µ—Ä–æ–π: {hero}\n"
        f"–†–æ–ª—å: {role}\n"
        f"–ê—Å–ø–µ–∫—Ç: {aspect}\n"
        f"–í—Ä–∞–≥–∏ –Ω–∞ –ª–∏–Ω–∏–∏: {enemy_lane_heroes}\n\n"
        "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 3-5 –±–∏–ª–¥–æ–≤ (BuildVariant) —Å –ø–æ–ª—è–º–∏: id, label, description.\n"
        "–û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –≤ JSON-–º–∞—Å—Å–∏–≤–µ."
    )

    response = chat_completion(
        system_msg="–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ Dota 2. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å –±–∏–ª–¥-–æ–ø—Ü–∏–∏.",
        user_msg=user_prompt,
        max_tokens=1000
    )

    if not response:
        return fallback_build_options(None)

    try:
        builds = json.loads(extract_json_block(response.content))
        return [BuildVariant(**b) for b in builds]
    except Exception as e:
        logger.exception(f"‚ùå Build options parse error: {e}")
        return fallback_build_options(None)

# ---------------------------- Detailed Build ----------------------------

def normalize_openai_detailed_response(parsed: Dict) -> Dict:
    if isinstance(parsed.get("builds"), list) and parsed["builds"]:
        first = parsed["builds"][0]
        for key in [
            "starting_items", "early_game_items", "mid_game_items", "late_game_items", "situational_items",
            "skill_build", "talents", "game_plan", "item_explanations"
        ]:
            parsed.setdefault(key, first.get(key))
    return parsed


def generate_detailed_build(
    hero: str,
    role: str,
    aspect: str,
    selected_build_id: str,
    enemy_heroes: List[str],
    ally_heroes: List[str]
) -> DetailedBuildResponse:
    cached = load_build_from_cache(selected_build_id)
    if cached:
        logger.info(f"‚úÖ Cache hit for build_id={selected_build_id}")
        return DetailedBuildResponse(**cached)

    user_prompt = (
        f"–ì–µ—Ä–æ–π: {hero}, –†–æ–ª—å: {role}, –ê—Å–ø–µ–∫—Ç: {aspect}\n"
        f"–ë–∏–ª–¥: {selected_build_id}\n"
        f"–í—Ä–∞–≥–∏: {enemy_heroes}\n"
        f"–°–æ—é–∑–Ω–∏–∫–∏: {ally_heroes}\n\n"
        "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π DetailedBuildResponse —Å –ø–æ–ª—è–º–∏:\n"
        "- starting_items, early_game_items, mid_game_items, late_game_items, situational_items\n"
        "- skill_build, talents, game_plan, item_explanations\n"
        "- warnings, source='openai', builds=[]\n"
        "–û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –≤ JSON."
    )

    response = chat_completion(
        system_msg="–¢—ã —Å—Ç—Ä–∞—Ç–µ–≥ –≤ Dota 2. –í–æ–∑–≤—Ä–∞—â–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –±–∏–ª–¥.",
        user_msg=user_prompt,
        max_tokens=1500
    )

    if not response:
        return fallback_detailed_build(hero, role, aspect, selected_build_id, enemy_heroes, ally_heroes)

    try:
        parsed = json.loads(extract_json_block(response.content))
        parsed = normalize_openai_detailed_response(parsed)
        parsed.setdefault("warnings", [])
        parsed.setdefault("source", "openai")
        parsed.setdefault("builds", [])

        if validate_openai_json(parsed):
            save_build_to_cache(selected_build_id, parsed)

        return DetailedBuildResponse(**parsed)

    except Exception as e:
        logger.exception(f"‚ùå Detailed build parsing failed: {e}")
        return fallback_detailed_build(hero, role, aspect, selected_build_id, enemy_heroes, ally_heroes)
